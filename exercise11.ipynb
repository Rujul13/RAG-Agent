{"cells":[{"source":["# Adding Self-Reflection to the Workflow\n","\n","We now have a deep research agent! It comprehensively researches a topic for us before providing a detailed answer. But we can do better!\n","\n","ðŸ§˜ LLMs are capable of self-reflection: they can read their own work, critique it, and provide feedback, allowing them to take a second try when they fall short.\n","\n","Let's add reflection to our deep research agent! This will involve several changes:\n","\n","* In `research` we'll store the research into the context, since we might need to use it multiple times\n","* We'll tell `write` that it can be triggered by a `RewriteEvent` in addition to a `WriteEvent`\n","* If it's a `RewriteEvent` we'll add the review as feedback to the prompt\n","* `review` will be changed to optionally emit a `RewriteEvent`\n","* We'll get the LLM to decide if the review returned by the agent is a \"bad\" or \"good\" review"],"metadata":{"id":"5b8dc78d-e945-42b1-bf52-9546fdcf0ce5"},"id":"5b8dc78d-e945-42b1-bf52-9546fdcf0ce5","cell_type":"markdown"},{"source":["Pre-reqs"],"metadata":{"id":"cdc18a2e-cc06-4725-9fc9-a9cd944717c1"},"id":"cdc18a2e-cc06-4725-9fc9-a9cd944717c1","cell_type":"markdown"},{"source":["!pip install llama-index -q -q"],"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":true},"executionCancelledAt":null,"executionTime":3253,"lastExecutedAt":1756670085923,"lastExecutedByKernel":"7b57e20c-f6d4-4a89-a2e4-c59e65bc6da2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install llama-index -q -q","id":"2b2091d7-cad5-484e-9d44-7154d1280a48"},"id":"2b2091d7-cad5-484e-9d44-7154d1280a48","cell_type":"code","execution_count":null,"outputs":[]},{"source":["!pip install tavily-python -q -q"],"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":true},"executionCancelledAt":null,"executionTime":3010,"lastExecutedAt":1756670088935,"lastExecutedByKernel":"7b57e20c-f6d4-4a89-a2e4-c59e65bc6da2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install tavily-python -q -q","id":"f69e06e6-5f46-480e-9e93-ba84d892e98e"},"id":"f69e06e6-5f46-480e-9e93-ba84d892e98e","cell_type":"code","execution_count":null,"outputs":[]},{"source":["from tavily import AsyncTavilyClient\n","from llama_index.core.agent.workflow import AgentWorkflow\n","from llama_index.llms.openai import OpenAI\n","import os\n","from openai import OpenAI as OpenAIClient\n","\n","raw_client = OpenAIClient()\n","\n","API_KEY   = raw_client.api_key\n","API_BASE  = raw_client.base_url\n","\n","tavily_api_key = os.environ[\"TAVILY_API_KEY\"]\n","\n","async def search_web(query: str) -> str:\n","    \"\"\"Useful for using the web to answer questions.\"\"\"\n","    client = AsyncTavilyClient(api_key=tavily_api_key)\n","    return str(await client.search(query))\n","\n","llm = OpenAI(model=\"gpt-4o-mini\", api_key=API_KEY, api_base=API_BASE)\n","\n","workflow = AgentWorkflow.from_tools_or_functions(\n","    [search_web],\n","    llm=llm,\n","    system_prompt=\"You are a helpful assistant that answers questions. If you don't know the answer, you can search the web for information.\",\n",")"],"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":true},"executionCancelledAt":null,"executionTime":3063,"lastExecutedAt":1756670091999,"lastExecutedByKernel":"7b57e20c-f6d4-4a89-a2e4-c59e65bc6da2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from tavily import AsyncTavilyClient\nfrom llama_index.core.agent.workflow import AgentWorkflow\nfrom llama_index.llms.openai import OpenAI\nimport os\nfrom openai import OpenAI as OpenAIClient\n\nraw_client = OpenAIClient()\n\nAPI_KEY   = raw_client.api_key   \nAPI_BASE  = raw_client.base_url\n\ntavily_api_key = os.environ[\"TAVILY_API_KEY\"]\n\nasync def search_web(query: str) -> str:\n    \"\"\"Useful for using the web to answer questions.\"\"\"\n    client = AsyncTavilyClient(api_key=tavily_api_key)\n    return str(await client.search(query))\n\nllm = OpenAI(model=\"gpt-4o-mini\", api_key=API_KEY, api_base=API_BASE)\n\nworkflow = AgentWorkflow.from_tools_or_functions(\n    [search_web],\n    llm=llm,\n    system_prompt=\"You are a helpful assistant that answers questions. If you don't know the answer, you can search the web for information.\",\n)","id":"3165d77f-16bb-434e-a3b6-a9c9972abb7d"},"id":"3165d77f-16bb-434e-a3b6-a9c9972abb7d","cell_type":"code","execution_count":null,"outputs":[]},{"source":["from llama_index.core.agent.workflow import FunctionAgent\n","from llama_index.core.workflow import (\n","    Event,\n","    StartEvent,\n","    StopEvent,\n","    Context,\n","    Workflow,\n","    step\n",")\n","\n","class FeedbackEvent(Event):\n","    feedback: str\n","\n","class ReviewEvent(Event):\n","    report: str\n","\n","class GenerateEvent(Event):\n","    research_topic: str\n","\n","class QuestionEvent(Event):\n","    question: str\n","\n","class AnswerEvent(Event):\n","    question: str\n","    answer: str\n","\n","class ProgressEvent(Event):\n","    msg: str\n","\n","question_agent = FunctionAgent(\n","    tools=[],\n","    llm=llm,\n","    verbose=False,\n","    system_prompt=\"\"\"You are part of a deep research system.\n","      Given a research topic, you should come up with a bunch of questions\n","      that a separate agent will answer in order to write a comprehensive\n","      report on that topic. To make it easy to answer the questions separately,\n","      you should provide the questions one per line. Don't include markdown\n","      or any preamble in your response, just a list of questions.\"\"\"\n",")\n","answer_agent = FunctionAgent(\n","    tools=[search_web],\n","    llm=llm,\n","    verbose=False,\n","    system_prompt=\"\"\"You are part of a deep research system.\n","      Given a specific question, your job is to come up with a deep answer\n","      to that question, which will be combined with other answers on the topic\n","      into a comprehensive report. You can search the web to get information\n","      on the topic, as many times as you need.\"\"\"\n",")\n","report_agent = FunctionAgent(\n","    tools=[],\n","    llm=llm,\n","    verbose=False,\n","    system_prompt=\"\"\"You are part of a deep research system.\n","      Given a set of answers to a set of questions, your job is to combine\n","      them all into a comprehensive report on the topic.\"\"\"\n",")"],"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":true},"executionCancelledAt":null,"executionTime":62,"lastExecutedAt":1756670092063,"lastExecutedByKernel":"7b57e20c-f6d4-4a89-a2e4-c59e65bc6da2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from llama_index.core.agent.workflow import FunctionAgent\nfrom llama_index.core.workflow import (\n    Event, \n    StartEvent,\n    StopEvent,\n    Context,\n    Workflow,\n    step\n)\n\nclass FeedbackEvent(Event):\n    feedback: str\n\nclass ReviewEvent(Event):\n    report: str\n\nclass GenerateEvent(Event):\n    research_topic: str\n\nclass QuestionEvent(Event):\n    question: str\n\nclass AnswerEvent(Event):\n    question: str\n    answer: str\n\nclass ProgressEvent(Event):\n    msg: str\n\nquestion_agent = FunctionAgent(\n    tools=[],\n    llm=llm,\n    verbose=False,\n    system_prompt=\"\"\"You are part of a deep research system.\n      Given a research topic, you should come up with a bunch of questions\n      that a separate agent will answer in order to write a comprehensive\n      report on that topic. To make it easy to answer the questions separately,\n      you should provide the questions one per line. Don't include markdown\n      or any preamble in your response, just a list of questions.\"\"\"\n)\nanswer_agent = FunctionAgent(\n    tools=[search_web],\n    llm=llm,\n    verbose=False,\n    system_prompt=\"\"\"You are part of a deep research system.\n      Given a specific question, your job is to come up with a deep answer\n      to that question, which will be combined with other answers on the topic\n      into a comprehensive report. You can search the web to get information\n      on the topic, as many times as you need.\"\"\"\n)\nreport_agent = FunctionAgent(\n    tools=[],\n    llm=llm,\n    verbose=False,\n    system_prompt=\"\"\"You are part of a deep research system.\n      Given a set of answers to a set of questions, your job is to combine\n      them all into a comprehensive report on the topic.\"\"\"\n)","id":"7cf206a3-531b-4f5f-b9df-fb76dceb10de"},"id":"7cf206a3-531b-4f5f-b9df-fb76dceb10de","cell_type":"code","execution_count":null,"outputs":[]},{"source":["review_agent = FunctionAgent(\n","    tools=[],\n","    llm=llm,\n","    verbose=False,\n","    system_prompt=\"\"\"You are part of a deep research system.\n","      Your job is to review a report that's been written and suggest\n","      questions that could have been asked to produce a more comprehensive\n","      report than the current version, or to decide that the current\n","      report is comprehensive enough.\"\"\"\n",")\n","\n","class DeepResearchWithReflectionWorkflow(Workflow):\n","\n","    @step\n","    async def setup(self, ctx: Context, ev: StartEvent) -> GenerateEvent:\n","        self.question_agent = ev.question_agent\n","        self.answer_agent = ev.answer_agent\n","        self.report_agent = ev.report_agent\n","        self.review_agent = ev.review_agent\n","        self.review_cycles = 0\n","\n","        ctx.write_event_to_stream(ProgressEvent(msg=\"Starting research\"))\n","\n","        return GenerateEvent(research_topic=ev.research_topic)\n","\n","    @step\n","    async def generate_questions(self, ctx: Context, ev: GenerateEvent | FeedbackEvent) -> QuestionEvent:\n","\n","        await ctx.set(\"research_topic\", ev.research_topic)\n","        ctx.write_event_to_stream(ProgressEvent(msg=f\"Research topic is {ev.research_topic}\"))\n","\n","        prompt = f\"\"\"Generate some questions on the topic <topic>{ev.research_topic}</topic>.\"\"\"\n","\n","        if isinstance(ev, FeedbackEvent):\n","            ctx.write_event_to_stream(ProgressEvent(msg=f\"Got feedback: {ev.feedback}\"))\n","            prompt += f\"\"\"You have previously researched this topic and\n","                got the following feedback, consisting of additional questions\n","                you might want to ask: <feedback>{ev.feedback}</feedback>.\n","                Keep this in mind when formulating your questions.\"\"\"\n","\n","        result = await self.question_agent.run(user_msg=prompt)\n","\n","        # Some basic string manipulation to get separate questions\n","        lines = str(result).split(\"\\n\")\n","        questions = [line.strip() for line in lines if line.strip() != \"\"]\n","\n","        # Record how many answers we're going to need to wait for\n","        await ctx.set(\"total_questions\", len(questions))\n","\n","        # Fire off multiple Answer Agents\n","        for question in questions:\n","            ctx.send_event(QuestionEvent(question=question))\n","\n","    @step\n","    async def answer_question(self, ctx: Context, ev: QuestionEvent) -> AnswerEvent:\n","\n","        result = await self.answer_agent.run(user_msg=f\"\"\"Research the answer to this\n","          question: <question>{ev.question}</question>. You can use web\n","          search to help you find information on the topic, as many times\n","          as you need. Return just the answer without preamble or markdown.\"\"\")\n","\n","        ctx.write_event_to_stream(ProgressEvent(msg=f\"\"\"Received question {ev.question}\n","            Came up with answer: {str(result)}\"\"\"))\n","\n","        return AnswerEvent(question=ev.question,answer=str(result))\n","\n","    @step\n","    async def write_report(self, ctx: Context, ev: AnswerEvent) -> ReviewEvent:\n","\n","        # CODE: store the answers in a variable\n","        research = ctx.collect_events(ev, [AnswerEvent] * await ctx.get(\"total_questions\"))\n","        # If we haven't received all the answers yet, this will be None\n","        if research is None:\n","            ctx.write_event_to_stream(ProgressEvent(msg=\"Collecting answers...\"))\n","            return None\n","\n","        ctx.write_event_to_stream(ProgressEvent(msg=\"Generating report...\"))\n","\n","        # Aggregate the questions and answers\n","        all_answers = \"\"\n","        for q_and_a in research:\n","            all_answers += f\"Question: {q_and_a.question}\\nAnswer: {q_and_a.answer}\\n\\n\"\n","\n","        # Prompt the report\n","        result = await self.report_agent.run(user_msg=f\"\"\"You are part of a deep research system.\n","          You have been given a complex topic on which to write a report:\n","          <topic>{await ctx.get(\"research_topic\")}.\n","\n","          Other agents have already come up with a list of questions about the\n","          topic and answers to those questions. Your job is to write a clear,\n","          thorough report that combines all the information from those answers.\n","\n","          Here are the questions and answers:\n","          <questions_and_answers>{all_answers}</questions_and_answers>\"\"\")\n","\n","        return ReviewEvent(report=str(result))\n","\n","    @step\n","    async def review(self, ctx: Context, ev: ReviewEvent) -> StopEvent | FeedbackEvent:\n","\n","        # CODE: call the review agent at this step\n","        result = await self.review_agent.run(user_msg=f\"\"\"You are part of a deep research system.\n","          You have just written a report about the topic {await ctx.get(\"research_topic\")}.\n","          Here is the report: <report>{ev.report}</report>\n","          Decide whether this report is sufficiently comprehensive.\n","          If it is, respond with just the string \"ACCEPTABLE\" and nothing else.\n","          If it needs more research, suggest some additional questions that could\n","          have been asked.\"\"\")\n","\n","        self.review_cycles += 1\n","\n","        # Either it's okay or we've already gone through 3 cycles\n","        if str(result) == \"ACCEPTABLE\" or self.review_cycles >= 3:\n","            return StopEvent(result=ev.report)\n","        else:\n","            ctx.write_event_to_stream(ProgressEvent(msg=\"Sending feedback\"))\n","            return FeedbackEvent(\n","                research_topic=await ctx.get(\"research_topic\"),\n","                feedback=str(result)\n","            )"],"metadata":{"executionCancelledAt":null,"executionTime":63,"lastExecutedAt":1756670092127,"lastExecutedByKernel":"7b57e20c-f6d4-4a89-a2e4-c59e65bc6da2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"review_agent = FunctionAgent(\n    tools=[],\n    llm=llm,\n    verbose=False,\n    system_prompt=\"\"\"You are part of a deep research system.\n      Your job is to review a report that's been written and suggest\n      questions that could have been asked to produce a more comprehensive\n      report than the current version, or to decide that the current\n      report is comprehensive enough.\"\"\"\n)\n\nclass DeepResearchWithReflectionWorkflow(Workflow):\n\n    @step\n    async def setup(self, ctx: Context, ev: StartEvent) -> GenerateEvent:\n        self.question_agent = ev.question_agent\n        self.answer_agent = ev.answer_agent\n        self.report_agent = ev.report_agent\n        self.review_agent = ev.review_agent\n        self.review_cycles = 0\n\n        ctx.write_event_to_stream(ProgressEvent(msg=\"Starting research\"))\n\n        return GenerateEvent(research_topic=ev.research_topic)\n\n    @step\n    async def generate_questions(self, ctx: Context, ev: GenerateEvent | FeedbackEvent) -> QuestionEvent:\n\n        await ctx.set(\"research_topic\", ev.research_topic)\n        ctx.write_event_to_stream(ProgressEvent(msg=f\"Research topic is {ev.research_topic}\"))\n\n        prompt = f\"\"\"Generate some questions on the topic <topic>{ev.research_topic}</topic>.\"\"\"\n\n        if isinstance(ev, FeedbackEvent):\n            ctx.write_event_to_stream(ProgressEvent(msg=f\"Got feedback: {ev.feedback}\"))\n            prompt += f\"\"\"You have previously researched this topic and\n                got the following feedback, consisting of additional questions\n                you might want to ask: <feedback>{ev.feedback}</feedback>.\n                Keep this in mind when formulating your questions.\"\"\"\n\n        result = await self.question_agent.run(user_msg=prompt)\n\n        # Some basic string manipulation to get separate questions\n        lines = str(result).split(\"\\n\")\n        questions = [line.strip() for line in lines if line.strip() != \"\"]\n\n        # Record how many answers we're going to need to wait for\n        await ctx.set(\"total_questions\", len(questions))\n\n        # Fire off multiple Answer Agents\n        for question in questions:\n            ctx.send_event(QuestionEvent(question=question))\n\n    @step\n    async def answer_question(self, ctx: Context, ev: QuestionEvent) -> AnswerEvent:\n\n        result = await self.answer_agent.run(user_msg=f\"\"\"Research the answer to this\n          question: <question>{ev.question}</question>. You can use web\n          search to help you find information on the topic, as many times\n          as you need. Return just the answer without preamble or markdown.\"\"\")\n\n        ctx.write_event_to_stream(ProgressEvent(msg=f\"\"\"Received question {ev.question}\n            Came up with answer: {str(result)}\"\"\"))\n\n        return AnswerEvent(question=ev.question,answer=str(result))\n\n    @step\n    async def write_report(self, ctx: Context, ev: AnswerEvent) -> ReviewEvent:\n\n        # CODE: store the answers in a variable\n        research = ctx.collect_events(ev, [AnswerEvent] * await ctx.get(\"total_questions\"))\n        # If we haven't received all the answers yet, this will be None\n        if research is None:\n            ctx.write_event_to_stream(ProgressEvent(msg=\"Collecting answers...\"))\n            return None\n\n        ctx.write_event_to_stream(ProgressEvent(msg=\"Generating report...\"))\n\n        # Aggregate the questions and answers\n        all_answers = \"\"\n        for q_and_a in research:\n            all_answers += f\"Question: {q_and_a.question}\\nAnswer: {q_and_a.answer}\\n\\n\"\n\n        # Prompt the report\n        result = await self.report_agent.run(user_msg=f\"\"\"You are part of a deep research system.\n          You have been given a complex topic on which to write a report:\n          <topic>{await ctx.get(\"research_topic\")}.\n\n          Other agents have already come up with a list of questions about the\n          topic and answers to those questions. Your job is to write a clear,\n          thorough report that combines all the information from those answers.\n\n          Here are the questions and answers:\n          <questions_and_answers>{all_answers}</questions_and_answers>\"\"\")\n\n        return ReviewEvent(report=str(result))\n\n    @step\n    async def review(self, ctx: Context, ev: ReviewEvent) -> StopEvent | FeedbackEvent:\n\n        # CODE: call the review agent at this step\n        result = await self.review_agent.run(user_msg=f\"\"\"You are part of a deep research system.\n          You have just written a report about the topic {await ctx.get(\"research_topic\")}.\n          Here is the report: <report>{ev.report}</report>\n          Decide whether this report is sufficiently comprehensive.\n          If it is, respond with just the string \"ACCEPTABLE\" and nothing else.\n          If it needs more research, suggest some additional questions that could\n          have been asked.\"\"\")\n\n        self.review_cycles += 1\n\n        # Either it's okay or we've already gone through 3 cycles\n        if str(result) == \"ACCEPTABLE\" or self.review_cycles >= 3:\n            return StopEvent(result=ev.report)\n        else:\n            ctx.write_event_to_stream(ProgressEvent(msg=\"Sending feedback\"))\n            return FeedbackEvent(\n                research_topic=await ctx.get(\"research_topic\"),\n                feedback=str(result)\n            )","id":"bbf8da41-dca2-46b0-b4d3-42daf46d7fe5"},"id":"bbf8da41-dca2-46b0-b4d3-42daf46d7fe5","cell_type":"code","execution_count":null,"outputs":[]},{"source":[" we've cached the report for the topic \"History of San Francisco\" to keep this solution fast so that you can see the outcome instantly.\n","\n","```\n","workflow = DeepResearchWithReflectionWorkflow(timeout=300)\n","handler = workflow.run(\n","    research_topic=\"History of San Francisco\",\n","    question_agent=question_agent,\n","    answer_agent=answer_agent,\n","    report_agent=report_agent,\n","    review_agent=review_agent\n",")\n","\n","async for ev in handler.stream_events():\n","    if isinstance(ev, ProgressEvent):\n","        print(ev.msg)\n","\n","final_result = await handler\n","print(\"==== The report ====\")\n","print(final_result)\n","```"],"metadata":{"id":"d33fd69f-eea6-41c1-a483-40ca8027f68f"},"id":"d33fd69f-eea6-41c1-a483-40ca8027f68f","cell_type":"markdown"},{"source":["import json\n","import os\n","import asyncio\n","\n","CACHE_PATH = \"sf_history_reflection_cache.json\"\n","CACHE_KEY = \"History of San Francisco\"\n","\n","# Load or initialize the cache\n","if os.path.exists(CACHE_PATH):\n","    with open(CACHE_PATH, \"r\") as f:\n","        full_cache = json.load(f)\n","else:\n","    full_cache = {}\n","\n","if CACHE_KEY in full_cache:\n","    cached_result = full_cache"],"metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1756670092176,"lastExecutedByKernel":"7b57e20c-f6d4-4a89-a2e4-c59e65bc6da2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import json\nimport os\nimport asyncio\n\nCACHE_PATH = \"sf_history_reflection_cache.json\"\nCACHE_KEY = \"History of San Francisco\"\n\n# Load or initialize the cache\nif os.path.exists(CACHE_PATH):\n    with open(CACHE_PATH, \"r\") as f:\n        full_cache = json.load(f)\nelse:\n    full_cache = {}\n\nif CACHE_KEY in full_cache:\n    cached_result = full_cache","jupyter":{"outputs_hidden":false,"source_hidden":true},"id":"eb4da819-aa46-414a-ad79-8312ed53647b"},"id":"eb4da819-aa46-414a-ad79-8312ed53647b","cell_type":"code","execution_count":null,"outputs":[]},{"source":["async def replay_cached():\n","    messages = [\n","        \"Starting research...\",\n","        f\"Research topic is: {CACHE_KEY}\",\n","        \"Collecting answers...\",\n","        \"Generating report...\",\n","        \"Reflecting on report...\",\n","        \"Sending feedback...\",\n","        \"Generating report...\",\n","        \"Reflecting on report...\",\n","        \"Sending feedback...\",\n","        \"Generating report...\",\n","        \"Reflecting on report...\",\n","    ]\n","    for msg in messages:\n","        await asyncio.sleep(0.4)\n","        print(msg)\n","\n","    print(\"==== The report ====\")\n","    print(cached_result)\n","\n","await replay_cached()"],"metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":605,"type":"stream"}},"id":"dc21d2ac-65cb-4751-816e-f9c2cac13fbf","outputId":"0f0b2a3e-aa6d-4f6c-d273-3a56e89123e4"},"id":"dc21d2ac-65cb-4751-816e-f9c2cac13fbf","cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Starting research...\nResearch topic is: History of San Francisco\nCollecting answers...\nGenerating report...\nReflecting on report...\nSending feedback...\nGenerating report...\nReflecting on report...\nSending feedback...\nGenerating report...\nReflecting on report...\n==== The report ====\n# Comprehensive Report on the History of San Francisco\n\nSan Francisco, a city known for its iconic landmarks and vibrant culture, has a rich and complex history shaped by various events, demographics, and social movements. This report delves into the key historical milestones, cultural influences, and socio-economic developments that have defined San Francisco from its early days to the present.\n\n## Founding and Early Development\n\nThe history of San Francisco begins with the Indigenous Ohlone people, who inhabited the Bay Area for thousands of years before European contact. The arrival of Spanish explorers in 1769 marked the beginning of European settlement, culminating in the establishment of the Presidio of San Francisco and Mission San Francisco de AsÃ­s in 1776. Following Mexico's independence from Spain in 1821, the area remained sparsely populated until the discovery of gold at Sutter's Mill in 1848, which triggered the California Gold Rush. This event transformed San Francisco from a modest settlement of around 800 residents into a bustling metropolis with a population exceeding 50,000 by 1855. San Francisco was officially incorporated as a city in 1850, solidifying its status as a key urban center in the American West.\n\n## Impact of the Gold Rush\n\nThe Gold Rush had a profound impact on San Francisco's growth and development. The city became the primary supply center for gold miners, leading to rapid urbanization and economic expansion. The demand for goods and services resulted in the establishment of numerous businesses, including hotels, saloons, and shops. Infrastructure development surged, with makeshift housing and roads constructed to accommodate the influx of newcomers. This period laid the foundation for San Francisco's future as a major economic and cultural hub.\n\n## The 1906 Earthquake and Fire\n\nThe catastrophic earthquake of 1906 and the subsequent fires devastated the city, destroying approximately 80% of its buildings and resulting in around 3,000 deaths. The disaster left 225,000 people homeless and prompted significant changes in urban planning and building codes. The rebuilding efforts introduced new architectural styles and technologies, reshaping the urban landscape and leading to denser housing in cleared areas. This event catalyzed a reevaluation of safety standards and urban development practices, influencing the city's growth trajectory.\n\n## Immigration and Demographic Changes\n\nImmigration has played a pivotal role in shaping San Francisco's demographics. The city experienced significant waves of immigration, particularly during the Gold Rush, attracting diverse populations, including Chinese, Irish, and German immigrants. The establishment of Chinatown, one of the largest and oldest in North America, exemplifies the cultural contributions of Chinese immigrants. In the early 20th century, San Francisco became a primary entry point for immigrants from Asia and Latin America, further enriching the city's multicultural identity. The Immigration and Naturalization Act of 1965 relaxed restrictions, leading to another wave of immigrants from countries like Vietnam, the Philippines, and Mexico. While these demographic shifts have led to challenges such as housing shortages and cultural tensions, they have ultimately contributed to the city's diversity and vibrancy.\n\n## Economic Evolution\n\nSan Francisco's economy has evolved significantly over the years. Initially a center for trade and commerce during the Gold Rush, the city transitioned to manufacturing and shipping by the late 1800s. The post-World War II era saw a shift towards services, particularly in finance, tourism, and technology. The late 20th-century tech boom solidified San Francisco's status as a global technology hub, attracting startups and established tech giants. Today, the city is recognized for its emphasis on innovation and high-tech industries, although it faces challenges such as high living costs and income disparities.\n\n## Cultural Movements\n\nSan Francisco has been the birthplace of several significant cultural movements. The Beat Generation of the 1950s, characterized by a rejection of conventional society, emerged in the city, with key figures like Jack Kerouac and Allen Ginsberg. The 1960s Hippie Movement, centered in the Haight-Ashbury neighborhood, promoted peace, love, and social change, culminating in the Summer of Love in 1967. San Francisco has also played a crucial role in the LGBTQ+ rights movement, hosting the first Gay Rights March in 1970 and becoming a sanctuary for LGBTQ+ individuals. The city's vibrant arts scene, including psychedelic art and music, has further contributed to its cultural legacy.\n\n## Historical Landmarks\n\nSan Francisco is home to several notable historical landmarks that reflect its rich history. Alcatraz Island, once a notorious federal prison, symbolizes law enforcement and justice. The Golden Gate Bridge, completed in 1937, stands as an engineering marvel and cultural icon. Coit Tower, built in 1933, honors the city's volunteer firefighters and showcases murals from the Great Depression era. The Palace of Fine Arts, constructed for the 1915 Panama-Pacific International Exposition, celebrates the city's recovery from the 1906 earthquake. Mission San Francisco de AsÃ­s, founded in 1776, is the oldest surviving structure in the city and a symbol of its early history.\n\n## Challenges: Housing and Homelessness\n\nSan Francisco has faced significant challenges, particularly regarding housing and homelessness. The housing crisis, exacerbated by high demand and limited supply, has led to skyrocketing rents and increased evictions, displacing long-term residents. The issue of homelessness has deep historical roots, with significant increases noted during economic downturns and cuts to mental health services. Gentrification has transformed neighborhoods, pushing out marginalized communities and altering the city's cultural fabric. These challenges reflect broader socio-economic trends and historical injustices that continue to affect San Francisco's residents.\n\n## Conclusion\n\nThe history of San Francisco is a tapestry woven from diverse threads of immigration, economic evolution, cultural movements, and social challenges. From its early days as a small settlement to its current status as a global city, San Francisco's journey has been marked by resilience and transformation. The city's unique geography, rich cultural heritage, and ongoing struggles for social justice continue to shape its identity and influence its future. As San Francisco navigates the complexities of modern urban life, it remains a vital center of innovation, diversity, and cultural expression.\n"}]},{"source":["In this run, we did three rounds of review! You can see the full looping workflow in the visualizer:\n","\n","<img width=\"660\" src=\"https://seldo.com/uploads/2025/Screenshot%202025-05-04%20at%205.39.32%E2%80%AFPM.png\">"],"metadata":{"id":"d623e3e1-bef5-4385-b00e-ef2a621b2201"},"id":"d623e3e1-bef5-4385-b00e-ef2a621b2201","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab","colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}